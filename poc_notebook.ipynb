{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c045a38-4208-462a-b050-3fab89383e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 19:49:51,081 - INFO - Initializing ollama provider with model llama3:8b\n",
      "2025-07-27 19:49:51,103 - INFO - Client initialized\n",
      "2025-07-27 19:49:51,118 - INFO - --- Loading DFD components from './output/dfd_components.json' ---\n",
      "2025-07-27 19:49:51,119 - INFO - --- DFD components loaded successfully ---\n",
      "2025-07-27 19:49:51,119 - INFO - \n",
      "--- Invoking Local LLM to generate STRIDE threats ---\n",
      "2025-07-27 19:49:51,120 - INFO - --- Prompt sent to LLM ---\n",
      "\n",
      "You are a senior cybersecurity analyst specializing in threat modeling using the STRIDE methodology (Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, Elevation of Privilege), aligned with 2025 standards like OWASP Top 10, NIST SP 800-53, and MITRE ATT&CK.\n",
      "\n",
      "Based on the provided Data Flow Diagram (DFD) components in JSON format, perform a comprehensive threat analysis. Use Chain-of-Thought reasoning:\n",
      "1. For each external entity, asset, process, and data flow, systematically apply all STRIDE categories where applicable.\n",
      "2. Describe threats considering trust boundaries, protocols, and potential attack vectors (e.g., injection, misconfiguration).\n",
      "3. Suggest mitigations with references to standards (e.g., \"NIST AC-6 for least privilege\").\n",
      "4. Assess impact (Low/Medium/High based on potential damage) and likelihood (Low/Medium/High based on exploitability).\n",
      "\n",
      "For each threat, include:\n",
      "- 'component_name': Affected asset, process, data flow, or entity.\n",
      "- 'stride_category': One STRIDE category.\n",
      "- 'threat_description': Clear, specific description (e.g., \"Attacker intercepts unencrypted data in transit leading to disclosure\").\n",
      "- 'mitigation_suggestion': Practical, actionable mitigation (e.g., \"Implement TLS 1.3 with certificate pinning\").\n",
      "- 'impact': Low/Medium/High.\n",
      "- 'likelihood': Low/Medium/High.\n",
      "- 'references': Array of strings (e.g., [\"OWASP A01:2021\", \"NIST SI-2\"]).\n",
      "\n",
      "DFD Components:\n",
      "---\n",
      "{\n",
      "  \"external_entities\": [\n",
      "    \"U\"\n",
      "  ],\n",
      "  \"assets\": [\n",
      "    \"DB_P\",\n",
      "    \"DB_B\"\n",
      "  ],\n",
      "  \"processes\": [\n",
      "    \"CDN\",\n",
      "    \"LB\",\n",
      "    \"WS\",\n",
      "    \"MQ\",\n",
      "    \"WRK\",\n",
      "    \"ADM\",\n",
      "    \"ADM_P\"\n",
      "  ],\n",
      "  \"data_flows\": [\n",
      "    {\n",
      "      \"source\": \"U\",\n",
      "      \"destination\": \"CDN\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"HTTPS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"CDN\",\n",
      "      \"destination\": \"LB\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"HTTPS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"LB\",\n",
      "      \"destination\": \"WS\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"HTTPS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"WS\",\n",
      "      \"destination\": \"DB_P\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"JDBC/ODBC over TLS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"WS\",\n",
      "      \"destination\": \"MQ\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"AMQP over TLS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"WRK\",\n",
      "      \"destination\": \"MQ\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"AMQP over TLS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"WRK\",\n",
      "      \"destination\": \"DB_P\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"JDBC/ODBC over TLS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"DB_B\",\n",
      "      \"destination\": \"DB_P\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"Backup Protocol over TLS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"ADM\",\n",
      "      \"destination\": \"ADM_P\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"HTTPS over VPN\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"ADM_P\",\n",
      "      \"destination\": \"LB\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"HTTPS\"\n",
      "    }\n",
      "  ],\n",
      "  \"trust_boundaries\": [\n",
      "    \"Public Zone to Edge Zone\",\n",
      "    \"Edge Zone to Application DMZ\",\n",
      "    \"Application DMZ to Internal Core\",\n",
      "    \"Internal Core to Data Zone\",\n",
      "    \"Management Zone to Application DMZ\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"timestamp\": \"2025-07-27T16:38:38.774870\",\n",
      "    \"source_document\": \"./docs/designdoc.docx\"\n",
      "  }\n",
      "}\n",
      "---\n",
      "\n",
      "Generate a JSON object with a key 'threats' (array of threat objects). Output ONLY the JSON, with no additional commentary or formatting.\n",
      "\n",
      "2025-07-27 19:50:05,251 - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "2025-07-27 19:50:05,253 - INFO - --- Raw LLM Response ---\n",
      "[\n",
      "  {\n",
      "    \"component_name\": \"U\",\n",
      "    \"stride_category\": \"Spoofing\",\n",
      "    \"threat_description\": \"Attacker impersonates user U to access sensitive data\",\n",
      "    \"mitigation_suggestion\": \"Implement MFA and rate limiting for all authentication attempts\",\n",
      "    \"impact\": \"High\",\n",
      "    \"likelihood\": \"Medium\",\n",
      "    \"references\": [\"OWASP A01:2021\", \"NIST AC-2\"]\n",
      "  },\n",
      "  {\n",
      "    \"component_name\": \"CDN\",\n",
      "    \"stride_category\": \"Tampering\",\n",
      "    \"threat_description\": \"Malicious actor injects malicious code into CDN's response\",\n",
      "    \"mitigation_suggestion\": \"Implement Web Application Firewall (WAF) and regular security updates for CDN\",\n",
      "    \"impact\": \"High\",\n",
      "    \"likelihood\": \"Medium\",\n",
      "    \"references\": [\"OWASP A03:2021\", \"NIST SI-3\"]\n",
      "  },\n",
      "  {\n",
      "    \"component_name\": \"LB\",\n",
      "    \"stride_category\": \"Repudiation\",\n",
      "    \"threat_description\": \"Attacker alters load balancer configuration to deny service to legitimate users\",\n",
      "    \"mitigation_suggestion\": \"Implement logging and monitoring for load balancer, and have a backup plan in place\",\n",
      "    \"impact\": \"High\",\n",
      "    \"likelihood\": \"Medium\",\n",
      "    \"references\": [\"OWASP A04:2021\", \"NIST AC-6\"]\n",
      "  },\n",
      "  {\n",
      "    \"component_name\": \"WS\",\n",
      "    \"stride_category\": \"Information Disclosure\",\n",
      "    \"threat_description\": \"Unencrypted data is transmitted from WS to DB_P, allowing eavesdropping\",\n",
      "    \"mitigation_suggestion\": \"Implement TLS 1.3 with certificate pinning for all data flows from WS to DB_P\",\n",
      "    \"impact\": \"High\",\n",
      "    \"likelihood\": \"Medium\",\n",
      "    \"references\": [\"OWASP A06:2021\", \"NIST SP 800-53\"]\n",
      "  },\n",
      "  {\n",
      "    \"component_name\": \"MQ\",\n",
      "    \"stride_category\": \"Denial of Service\",\n",
      "    \"threat_description\": \"Malicious actor floods MQ with messages, causing performance degradation or failure\",\n",
      "    \"mitigation_suggestion\": \"Implement message queuing and dead-letter queues to handle malformed messages\",\n",
      "    \"impact\": \"High\",\n",
      "    \"likelihood\": \"Medium\",\n",
      "    \"references\": [\"OWASP A09:2021\", \"MITRE ATT&CK\"]\n",
      "  },\n",
      "  {\n",
      "    \"component_name\": \"DB_P\",\n",
      "    \"stride_category\": \"Elevation of Privilege\",\n",
      "    \"threat_description\": \"Insufficient access controls allow an attacker to escalate privileges within DB_P\",\n",
      "    \"mitigation_suggestion\": \"Implement least privilege and role-based access control for all database users\",\n",
      "    \"impact\": \"High\",\n",
      "    \"likelihood\": \"Medium\",\n",
      "    \"references\": [\"NIST AC-6\", \"MITRE ATT&CK\"]\n",
      "  },\n",
      "  {\n",
      "    \"component_name\": \"ADM_P\",\n",
      "    \"stride_category\": \"Denial of Service\",\n",
      "    \"threat_description\": \"Malicious actor sends a large number of HTTPS requests to ADM_P, overwhelming the system\",\n",
      "    \"mitigation_suggestion\": \"Implement rate limiting and logging for all administrative access\",\n",
      "    \"impact\": \"High\",\n",
      "    \"likelihood\": \"Medium\",\n",
      "    \"references\": [\"OWASP A09:2021\", \"NIST AC-7\"]\n",
      "  }\n",
      "]\n",
      "2025-07-27 19:50:18,652 - INFO - HTTP Request: POST http://localhost:11434/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-27 19:50:18,655 - INFO - --- JSON output validated successfully ---\n",
      "2025-07-27 19:50:18,658 - INFO - \n",
      "--- LLM Output (Identified Threats) ---\n",
      "2025-07-27 19:50:18,659 - INFO - \n",
      "--- Identified threats successfully saved to './output/identified_threats.json' ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"threats\": [\n",
      "    {\n",
      "      \"component_name\": \"U\",\n",
      "      \"stride_category\": \"Information Disclosure\",\n",
      "      \"threat_description\": \"Unencrypted data transmitted from U to CDN potentially disclosed\",\n",
      "      \"mitigation_suggestion\": \"Implement end-to-end encryption; Use HTTPS protocol\",\n",
      "      \"impact\": \"Medium\",\n",
      "      \"likelihood\": \"High\",\n",
      "      \"references\": [\n",
      "        \"OWASP A01:2021\",\n",
      "        \"NIST SI-2\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"component_name\": \"CDN\",\n",
      "      \"stride_category\": \"Tampering\",\n",
      "      \"threat_description\": \"Malicious actor intercepts and modifies data in transit from CDN to LB\",\n",
      "      \"mitigation_suggestion\": \"Implement integrity checking; Use digital signatures\",\n",
      "      \"impact\": \"High\",\n",
      "      \"likelihood\": \"Medium\",\n",
      "      \"references\": [\n",
      "        \"OWASP A03:2021\",\n",
      "        \"MITRE CA-8\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"component_name\": \"LB\",\n",
      "      \"stride_category\": \"Elevation of Privilege\",\n",
      "      \"threat_description\": \"Unprivileged actor gains elevated privileges on LB, potentially leading to DoS\",\n",
      "      \"mitigation_suggestion\": \"Implement least privilege; Restrict unnecessary access\",\n",
      "      \"impact\": \"High\",\n",
      "      \"likelihood\": \"Medium\",\n",
      "      \"references\": [\n",
      "        \"NIST AC-6\",\n",
      "        \"MITRE AU-5\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"component_name\": \"WS\",\n",
      "      \"stride_category\": \"Denial of Service\",\n",
      "      \"threat_description\": \"Volume-based DoS attack on WS, impacting application availability and performance\",\n",
      "      \"mitigation_suggestion\": \"Implement rate limiting; Monitor for suspicious activity\",\n",
      "      \"impact\": \"High\",\n",
      "      \"likelihood\": \"Medium\",\n",
      "      \"references\": [\n",
      "        \"OWASP A04:2021\",\n",
      "        \"NIST AC-2\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"component_name\": \"DB_P\",\n",
      "      \"stride_category\": \"Repudiation\",\n",
      "      \"threat_description\": \"Insider attempts to discredit or deny attacks on DB_P, potentially compromising audit logs\",\n",
      "      \"mitigation_suggestion\": \"Implement tamper-evident logging; Conduct regular auditing and monitoring\",\n",
      "      \"impact\": \"High\",\n",
      "      \"likelihood\": \"Low\",\n",
      "      \"references\": [\n",
      "        \"OWASP A05:2021\",\n",
      "        \"NIST AC-2\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"component_name\": \"ADM_P\",\n",
      "      \"stride_category\": \"Spoofing\",\n",
      "      \"threat_description\": \"Attackers impersonate ADM_P, potentially gaining unauthorized access to administrative functions\",\n",
      "      \"mitigation_suggestion\": \"Implement multi-factor authentication; Conduct regular security audits\",\n",
      "      \"impact\": \"High\",\n",
      "      \"likelihood\": \"Medium\",\n",
      "      \"references\": [\n",
      "        \"OWASP A07:2021\",\n",
      "        \"MITRE CA-7\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"timestamp\": \"2025-07-27T19:50:18.655020\",\n",
      "    \"source_dfd\": \"./output/dfd_components.json\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# --- Dependencies ---\n",
    "# Ensure you have these packages installed. You can install them using pip:\n",
    "# pip install langchain langchain-community langchain-ollama python-dotenv pydantic logging instructor\n",
    "\n",
    "import os\n",
    "import json\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import logging\n",
    "import instructor\n",
    "from ollama import Client  # Added for raw response debugging\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration ---\n",
    "# Use environment variables for paths and settings\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"llama3:8b\")  # Changed default to a more reliable model for testing\n",
    "INPUT_DIR = os.getenv(\"INPUT_DIR\", \"./output\")\n",
    "DFD_INPUT_PATH = os.getenv(\"DFD_INPUT_PATH\", os.path.join(INPUT_DIR, \"dfd_components.json\"))\n",
    "THREATS_OUTPUT_PATH = os.getenv(\"THREATS_OUTPUT_PATH\", os.path.join(INPUT_DIR, \"identified_threats.json\"))\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Ensure output directory exists early\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Initialize LLM with Instructor for schema enforcement\n",
    "llm = instructor.from_provider(f\"ollama/{LLM_MODEL}\", mode=instructor.Mode.JSON_SCHEMA)\n",
    "\n",
    "# Added: Raw Ollama client for debugging\n",
    "ollama_client = Client()\n",
    "\n",
    "# --- Threat Schema for Validation ---\n",
    "class Threat(BaseModel):\n",
    "    component_name: str = Field(description=\"Affected asset, process, data flow, or entity.\")\n",
    "    stride_category: str = Field(description=\"One STRIDE category: Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, Elevation of Privilege.\")\n",
    "    threat_description: str = Field(description=\"Clear, specific description of the threat.\")\n",
    "    mitigation_suggestion: str = Field(description=\"Practical, actionable mitigation.\")\n",
    "    impact: str = Field(description=\"Low/Medium/High based on potential damage.\")\n",
    "    likelihood: str = Field(description=\"Low/Medium/High based on exploitability.\")\n",
    "    references: list[str] = Field(description=\"Array of standard references (e.g., ['OWASP A01:2021', 'NIST SI-2']).\")\n",
    "\n",
    "class Threats(BaseModel):\n",
    "    threats: list[Threat]\n",
    "\n",
    "class ThreatsOutput(BaseModel):\n",
    "    threats: list[Threat]\n",
    "    metadata: dict\n",
    "\n",
    "# --- Sample DFD for Testing (if input is empty) ---\n",
    "SAMPLE_DFD = {\n",
    "    \"external_entities\": [\"User\", \"Attacker\"],\n",
    "    \"processes\": [\"Web Application\", \"Authentication Service\"],\n",
    "    \"data_stores\": [\"User Database\"],\n",
    "    \"data_flows\": [\n",
    "        {\n",
    "            \"from\": \"User\",\n",
    "            \"to\": \"Web Application\",\n",
    "            \"data\": \"Login Credentials\",\n",
    "            \"protocol\": \"HTTP\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"Web Application\",\n",
    "            \"to\": \"User Database\",\n",
    "            \"data\": \"Query User Data\",\n",
    "            \"protocol\": \"SQL\"\n",
    "        }\n",
    "    ],\n",
    "    \"trust_boundaries\": [\"Internet to DMZ\", \"DMZ to Internal Network\"]\n",
    "}\n",
    "\n",
    "# --- Load DFD Components ---\n",
    "logger.info(f\"--- Loading DFD components from '{DFD_INPUT_PATH}' ---\")\n",
    "try:\n",
    "    with open(DFD_INPUT_PATH, 'r') as f:\n",
    "        dfd_data = json.load(f)\n",
    "    if not dfd_data:  # Added: Check for empty data\n",
    "        logger.warning(\"--- DFD data is empty. Using sample DFD for testing ---\")\n",
    "        dfd_data = SAMPLE_DFD\n",
    "    logger.info(\"--- DFD components loaded successfully ---\")\n",
    "except FileNotFoundError:\n",
    "    logger.warning(f\"--- Input file not found at '{DFD_INPUT_PATH}'. Using sample DFD for testing ---\")\n",
    "    dfd_data = SAMPLE_DFD\n",
    "except json.JSONDecodeError:\n",
    "    logger.error(f\"--- FATAL ERROR: Could not parse JSON from '{DFD_INPUT_PATH}' ---\")\n",
    "    logger.error(\"The file may be corrupted or empty. Using sample DFD for testing.\")\n",
    "    dfd_data = SAMPLE_DFD\n",
    "except Exception as e:\n",
    "    logger.error(f\"--- FATAL ERROR: An unexpected error occurred while loading DFD components ---\")\n",
    "    logger.error(f\"Error details: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# --- Prompt Engineering for Threat Generation ---\n",
    "threat_prompt_template = \"\"\"\n",
    "You are a senior cybersecurity analyst specializing in threat modeling using the STRIDE methodology (Spoofing, Tampering, Repudiation, Information Disclosure, Denial of Service, Elevation of Privilege), aligned with 2025 standards like OWASP Top 10, NIST SP 800-53, and MITRE ATT&CK.\n",
    "\n",
    "Based on the provided Data Flow Diagram (DFD) components in JSON format, perform a comprehensive threat analysis. Use Chain-of-Thought reasoning:\n",
    "1. For each external entity, asset, process, and data flow, systematically apply all STRIDE categories where applicable.\n",
    "2. Describe threats considering trust boundaries, protocols, and potential attack vectors (e.g., injection, misconfiguration).\n",
    "3. Suggest mitigations with references to standards (e.g., \"NIST AC-6 for least privilege\").\n",
    "4. Assess impact (Low/Medium/High based on potential damage) and likelihood (Low/Medium/High based on exploitability).\n",
    "\n",
    "For each threat, include:\n",
    "- 'component_name': Affected asset, process, data flow, or entity.\n",
    "- 'stride_category': One STRIDE category.\n",
    "- 'threat_description': Clear, specific description (e.g., \"Attacker intercepts unencrypted data in transit leading to disclosure\").\n",
    "- 'mitigation_suggestion': Practical, actionable mitigation (e.g., \"Implement TLS 1.3 with certificate pinning\").\n",
    "- 'impact': Low/Medium/High.\n",
    "- 'likelihood': Low/Medium/High.\n",
    "- 'references': Array of strings (e.g., [\"OWASP A01:2021\", \"NIST SI-2\"]).\n",
    "\n",
    "DFD Components:\n",
    "---\n",
    "{dfd_json}\n",
    "---\n",
    "\n",
    "Generate a JSON object with a key 'threats' (array of threat objects). Output ONLY the JSON, with no additional commentary or formatting.\n",
    "\"\"\"\n",
    "\n",
    "threat_prompt = ChatPromptTemplate.from_template(threat_prompt_template)\n",
    "\n",
    "# --- Invocation and Output ---\n",
    "logger.info(\"\\n--- Invoking Local LLM to generate STRIDE threats ---\")\n",
    "try:\n",
    "    # Convert the loaded DFD dictionary back to a JSON string for the prompt\n",
    "    dfd_json_string = json.dumps(dfd_data, indent=2)\n",
    "\n",
    "    # Generate messages from the prompt template\n",
    "    messages = threat_prompt.format_messages(dfd_json=dfd_json_string)\n",
    "\n",
    "    # Added: Log the prompt for debugging\n",
    "    logger.info(f\"--- Prompt sent to LLM ---\\n{messages[0].content}\")\n",
    "\n",
    "    # Added: Call raw Ollama for response debugging (before Instructor)\n",
    "    raw_response = ollama_client.chat(model=LLM_MODEL, messages=[{\"role\": \"user\", \"content\": messages[0].content}])\n",
    "    logger.info(f\"--- Raw LLM Response ---\\n{raw_response['message']['content']}\")\n",
    "\n",
    "    # Invoke the LLM with Instructor for structured output\n",
    "    threats_obj = llm.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": messages[0].content}],\n",
    "        response_model=Threats,\n",
    "        max_retries=5  # Increased for better handling\n",
    "    )\n",
    "\n",
    "    threats_dict = threats_obj.model_dump()\n",
    "    \n",
    "    # Add metadata\n",
    "    threats_dict[\"metadata\"] = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"source_dfd\": DFD_INPUT_PATH\n",
    "    }\n",
    "    \n",
    "    # Validate the output against schema (Instructor already enforces, but double-check)\n",
    "    try:\n",
    "        validated = ThreatsOutput(**threats_dict)\n",
    "        logger.info(\"--- JSON output validated successfully ---\")\n",
    "    except ValidationError as ve:\n",
    "        logger.error(f\"--- JSON validation failed: {ve} ---\")\n",
    "        raise\n",
    "    \n",
    "    # Save the threats to a new file\n",
    "    with open(THREATS_OUTPUT_PATH, 'w') as f:\n",
    "        json.dump(threats_dict, f, indent=2)\n",
    "        \n",
    "    logger.info(\"\\n--- LLM Output (Identified Threats) ---\")\n",
    "    print(json.dumps(threats_dict, indent=2))\n",
    "    logger.info(f\"\\n--- Identified threats successfully saved to '{THREATS_OUTPUT_PATH}' ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"\\n--- An error occurred during threat generation ---\")\n",
    "    logger.error(f\"Error: {e}\")\n",
    "    logger.error(\"This could be due to the LLM not returning a well-formed JSON object or an issue with the input data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dedb0223-adbe-438a-b6b3-eb6ce3a9f852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 13:17:02,805 - INFO - --- Ollama client initialized successfully on port 11434 ---\n",
      "2025-07-28 13:17:02,821 - INFO - --- Raw Ollama client initialized successfully on port 11434 ---\n",
      "2025-07-28 13:17:02,861 - INFO - HTTP Request: GET http://aioverlord:11434/api/tags \"HTTP/1.1 200 OK\"\n",
      "2025-07-28 13:17:02,861 - INFO - --- Ollama server health check successful on port 11434. Available models: [Model(model='llama3-70b-m3max:latest', modified_at=datetime.datetime(2025, 7, 28, 11, 7, 1, 64630, tzinfo=TzInfo(+02:00)), digest='11a9abedc8a182544453e5f23f6f425ed0d551200cdaba1aef62e626982d5c05', size=39969745456, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='70.6B', quantization_level='Q4_0')), Model(model='llama3:70b-instruct', modified_at=datetime.datetime(2025, 7, 28, 10, 7, 48, 277784, tzinfo=TzInfo(+02:00)), digest='786f3184aec0e907952488b865362bdaa38180739a9881a8190d85bad8cab893', size=39969745349, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='70.6B', quantization_level='Q4_0')), Model(model='WhiteRabbitNeo/Llama-3.1-WhiteRabbitNeo-2-70B:latest', modified_at=datetime.datetime(2025, 7, 23, 14, 41, 7, 221280, tzinfo=TzInfo(+02:00)), digest='dbdba53cb1edb8ef20ae246d23a2ac1326c99528e4d3678ca9288330378dff5e', size=39969733685, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='70.6B', quantization_level='Q4_0')), Model(model='llama3:70b-instruct-q4_K_M', modified_at=datetime.datetime(2025, 7, 23, 11, 24, 58, 31807, tzinfo=TzInfo(+02:00)), digest='f04e196898af0f71e9e94bf46ab8807e3a873acd0831a5caf353ebf839926921', size=42520406471, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='70.6B', quantization_level='Q4_K_M')), Model(model='llama3:instruct', modified_at=datetime.datetime(2025, 6, 3, 18, 54, 22, 105913, tzinfo=TzInfo(+02:00)), digest='365c0bd3c000a25d28ddbf732fe1c6add414de7275464c4e4d1c3b5fcb5d8ad1', size=4661224676, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_0')), Model(model='qwq:32b', modified_at=datetime.datetime(2025, 6, 3, 13, 12, 59, 49515, tzinfo=TzInfo(+02:00)), digest='009cb3f08d74437380f3b84194c1bd34f1cc3d95a2bb87241d89387fc22a9ddf', size=19851349657, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='32.8B', quantization_level='Q4_K_M')), Model(model='gemma3:12b', modified_at=datetime.datetime(2025, 6, 3, 11, 3, 22, 672064, tzinfo=TzInfo(+02:00)), digest='f4031aab637d1ffa37b42570452ae0e4fad0314754d17ded67322e4b95836f8a', size=8149190253, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='12.2B', quantization_level='Q4_K_M'))] ---\n",
      "2025-07-28 13:17:02,864 - INFO - --- Loading DFD components from './output/dfd_components.json' ---\n",
      "2025-07-28 13:17:02,864 - INFO - --- DFD components loaded successfully ---\n",
      "2025-07-28 13:17:02,865 - INFO - \n",
      "--- Invoking Local LLM to generate STRIDE threats ---\n",
      "2025-07-28 13:17:02,865 - INFO - --- Generation Prompt sent to LLM ---\n",
      "\n",
      "You are a cybersecurity architect specializing in threat modeling using the STRIDE framework. Your task is to generate a complete list of relevant threats based on the provided DFD components in JSON format.\n",
      "\n",
      "STRIDE categories must be exactly one of: \n",
      "- S: Spoofing\n",
      "- T: Tampering\n",
      "- R: Repudiation\n",
      "- I: Information Disclosure\n",
      "- D: Denial of Service\n",
      "- E: Elevation of Privilege\n",
      "\n",
      "Do not use any other categories or variations. Generate threats covering ALL components, including:\n",
      "- External entities (e.g., \"User\")\n",
      "- Processes (e.g., \"Web Application\")\n",
      "- Assets (data stores, e.g., \"User Database\")\n",
      "- Data flows (label as \"Source to Destination\", e.g., \"User to Web Application\")\n",
      "- Trust boundaries (e.g., \"Internet to DMZ\")\n",
      "\n",
      "For each component, explicitly consider all six STRIDE categories (S, T, R, I, D, E) and generate threats for each where realistically applicable, aiming for at least 5-6 threats per component to ensure broad and comprehensive coverage. Justify omissions internally if a category truly does not apply, but prioritize inclusion to avoid gaps.\n",
      "\n",
      "For each threat, output strictly in this JSON structure:\n",
      "{\n",
      "  \"component_name\": \"Affected component (e.g., 'User to Web Application' or 'User Database')\",\n",
      "  \"stride_category\": \"One letter: S, T, R, I, D, or E\",\n",
      "  \"threat_description\": \"Clear, specific description tied to the component, including attack vectors (e.g., 'via MITM on weak TLS leading to PII exposure and regulatory fines'). Reference protocols from the DFD (e.g., HTTPS, AMQP).\",\n",
      "  \"mitigation_suggestion\": \"Practical, actionable mitigation (e.g., 'Implement HTTPS with certificate pinning and HSTS').\",\n",
      "  \"impact\": \"Low, Medium, or High\",\n",
      "  \"likelihood\": \"Low, Medium, or High\",\n",
      "  \"references\": [\"Array of 1-3 valid strings (e.g., 'OWASP A01:2021', 'NIST SP 800-53 SC-28', 'CWE-89')\"],\n",
      "  \"risk_score\": \"Critical, High, Medium, or Low (calculate as: Critical if Impact=High and Likelihood=Medium/High; High if Impact=High and Likelihood=Low or Impact=Medium and Likelihood=High; Medium if Impact=Medium and Likelihood=Medium/Low or Impact=Low and Likelihood=High; Low otherwise)\"\n",
      "}\n",
      "\n",
      "Think step-by-step internally before generating:\n",
      "1. Parse the DFD JSON: Explicitly list all external_entities, processes, assets (data_stores), data_flows (as 'source to destination'), and trust_boundaries. Ensure every item is addressed.\n",
      "2. For each listed component, brainstorm applicable STRIDE threats: Consider all six categories, identifying typical risks (e.g., data flows vulnerable to T and I due to transit; processes to D and E from overload or vulns; data stores to I at rest). Generate at least one threat per category unless impossible, to achieve 5-6 per component.\n",
      "3. Make threats realistic and specific: Include attack vectors (e.g., SQL injection for tampering), consequences (e.g., data breach leading to fines), and reference DFD protocols/architecture.\n",
      "4. Avoid duplicates: Ensure no identical threats across components; vary descriptions even for similar risks.\n",
      "5. Assign impact/likelihood with justification: Base on exposure (e.g., public-facing = higher likelihood) and calculate risk_score accurately.\n",
      "6. Use only valid references from: OWASP Top 10 2021 (A01-A10 only, e.g., A03:2021 for Injection), NIST SP 800-series (e.g., 800-53, 800-63B, 800-52), CWE (e.g., CWE-89), MITRE ATT&CK (e.g., T1071). Limit to 1-3 per threat; do not invent invalid ones like A11.\n",
      "\n",
      "Examples of good threats:\n",
      "{\n",
      "  \"component_name\": \"User to Web Application\",\n",
      "  \"stride_category\": \"S\",\n",
      "  \"threat_description\": \"Attacker spoofs user identity via phishing to send fake login credentials over HTTP, leading to account takeover and unauthorized access.\",\n",
      "  \"mitigation_suggestion\": \"Implement strong authentication such as OAuth 2.0 with JWT tokens and MFA.\",\n",
      "  \"impact\": \"High\",\n",
      "  \"likelihood\": \"Medium\",\n",
      "  \"references\": [\"OWASP A05:2021\", \"NIST SP 800-63B\", \"CWE-287\"],\n",
      "  \"risk_score\": \"Critical\"\n",
      "},\n",
      "{\n",
      "  \"component_name\": \"User Database\",\n",
      "  \"stride_category\": \"I\",\n",
      "  \"threat_description\": \"Unauthorized access via SQL injection leading to data leakage of sensitive PII, resulting in privacy violations and fines.\",\n",
      "  \"mitigation_suggestion\": \"Encrypt data at rest using AES-256, implement parameterized queries, and enforce least-privilege access controls.\",\n",
      "  \"impact\": \"High\",\n",
      "  \"likelihood\": \"Medium\",\n",
      "  \"references\": [\"OWASP A04:2021\", \"NIST SP 800-53 SC-28\", \"CWE-200\"],\n",
      "  \"risk_score\": \"Critical\"\n",
      "}\n",
      "\n",
      "Negative examples to avoid:\n",
      "- Invalid reference like \"OWASP A11:2021\" (Top 10 only has A01-A10).\n",
      "- Generic description like \"Unauthorized access to database leading to data leakage\" (add vectors/consequences).\n",
      "- Missing STRIDE coverage without internal justification.\n",
      "- Fewer than 5 threats per component, leading to gaps.\n",
      "\n",
      "DFD Components JSON:\n",
      "{\n",
      "  \"external_entities\": [\n",
      "    \"U\"\n",
      "  ],\n",
      "  \"assets\": [\n",
      "    \"DB_P\",\n",
      "    \"DB_B\"\n",
      "  ],\n",
      "  \"processes\": [\n",
      "    \"CDN\",\n",
      "    \"LB\",\n",
      "    \"WS\",\n",
      "    \"MQ\",\n",
      "    \"WRK\",\n",
      "    \"ADM\",\n",
      "    \"ADM_P\"\n",
      "  ],\n",
      "  \"data_flows\": [\n",
      "    {\n",
      "      \"source\": \"U\",\n",
      "      \"destination\": \"CDN\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"HTTPS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"CDN\",\n",
      "      \"destination\": \"LB\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"HTTPS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"LB\",\n",
      "      \"destination\": \"WS\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"HTTPS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"WS\",\n",
      "      \"destination\": \"DB_P\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"JDBC/ODBC over TLS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"WS\",\n",
      "      \"destination\": \"MQ\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"AMQP over TLS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"WRK\",\n",
      "      \"destination\": \"MQ\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"AMQP over TLS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"WRK\",\n",
      "      \"destination\": \"DB_P\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"JDBC/ODBC over TLS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"DB_B\",\n",
      "      \"destination\": \"DB_P\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"Backup Protocol over TLS\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"ADM\",\n",
      "      \"destination\": \"ADM_P\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"HTTPS over VPN\"\n",
      "    },\n",
      "    {\n",
      "      \"source\": \"ADM_P\",\n",
      "      \"destination\": \"LB\",\n",
      "      \"data_description\": \"\",\n",
      "      \"protocol\": \"HTTPS\"\n",
      "    }\n",
      "  ],\n",
      "  \"trust_boundaries\": [\n",
      "    \"Public Zone to Edge Zone\",\n",
      "    \"Edge Zone to Application DMZ\",\n",
      "    \"Application DMZ to Internal Core\",\n",
      "    \"Internal Core to Data Zone\",\n",
      "    \"Management Zone to Application DMZ\"\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"timestamp\": \"2025-07-27T16:38:38.774870\",\n",
      "    \"source_document\": \"./docs/designdoc.docx\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Output ONLY a JSON object with:\n",
      "- \"threats\": [array of threat objects, sorted by risk_score descending (Critical first, then High, Medium, Low)]\n",
      "\n",
      "Do not include metadata or any other keys. Output ONLY the JSON, with no additional text, commentary, reasoning, or formatting.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 230\u001b[39m\n\u001b[32m    227\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Generation Prompt sent to LLM ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mgen_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    229\u001b[39m \u001b[38;5;66;03m# Call raw Ollama for response debugging\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m raw_gen_response = \u001b[43mollama_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLLM_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Raw LLM Generation Response ---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mraw_gen_response[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m# Invoke with Instructor for structured output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/ollama/_client.py:342\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, think, format, options, keep_alive)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    298\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    299\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    308\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    309\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    310\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    311\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    340\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    341\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m      \u001b[49m\u001b[43mthink\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/ollama/_client.py:180\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    176\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    178\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/ollama/_client.py:120\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    119\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m     r.raise_for_status()\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpx/_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Dependencies ---\n",
    "# Ensure you have these packages installed. You can install them using pip:\n",
    "# pip install instructor openai pydantic logging python-dotenv\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import logging\n",
    "from ollama import Client  # For raw debugging\n",
    "import instructor\n",
    "from openai import OpenAI  # Wrapper for Ollama\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration ---\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"llama3-70b-m3max:latest\")\n",
    "INPUT_DIR = os.getenv(\"INPUT_DIR\", \"./output\")\n",
    "DFD_INPUT_PATH = os.getenv(\"DFD_INPUT_PATH\", os.path.join(INPUT_DIR, \"dfd_components.json\"))\n",
    "THREATS_OUTPUT_PATH = os.getenv(\"THREATS_OUTPUT_PATH\", os.path.join(INPUT_DIR, \"identified_threats.json\"))\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Initialize Ollama client with Instructor (using OpenAI wrapper)\n",
    "try:\n",
    "    client = instructor.from_openai(\n",
    "        OpenAI(\n",
    "            base_url=\"http://aioverlord:11434/v1\",\n",
    "            api_key=\"ollama\",  # Required but unused\n",
    "        ),\n",
    "        mode=instructor.Mode.JSON,  # Use JSON mode for Ollama\n",
    "    )\n",
    "    logger.info(\"--- Ollama client initialized successfully on port 11434 ---\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"--- Failed to initialize Ollama client on port 11434: {e} ---\")\n",
    "    raise\n",
    "\n",
    "# Raw Ollama client for debugging\n",
    "try:\n",
    "    ollama_client = Client(host=\"http://aioverlord:11434\")\n",
    "    logger.info(\"--- Raw Ollama client initialized successfully on port 11434 ---\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"--- Failed to initialize raw Ollama client on port 11434: {e} ---\")\n",
    "    raise\n",
    "\n",
    "# Health check: Ping the server by listing models (or any lightweight endpoint)\n",
    "try:\n",
    "    models_response = ollama_client.list()\n",
    "    logger.info(f\"--- Ollama server health check successful on port 11434. Available models: {models_response.get('models', 'None listed')} ---\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"--- Ollama server health check failed on port 11434: {e} ---\")\n",
    "    raise\n",
    "\n",
    "# --- Threat Schema for Validation ---\n",
    "class Threat(BaseModel):\n",
    "    component_name: str = Field(description=\"Affected asset, process, data flow, or entity.\")\n",
    "    stride_category: str = Field(description=\"One letter: S, T, R, I, D, or E.\")  # Aligned with prompt\n",
    "    threat_description: str = Field(description=\"Clear, specific description of the threat, including attack vectors and consequences.\")\n",
    "    mitigation_suggestion: str = Field(description=\"Practical, actionable mitigation.\")\n",
    "    impact: str = Field(description=\"Low, Medium, or High based on potential damage.\")\n",
    "    likelihood: str = Field(description=\"Low, Medium, or High based on exploitability.\")\n",
    "    references: list[str] = Field(description=\"Array of 1-3 valid references (e.g., ['OWASP A01:2021', 'NIST SP 800-53 SC-28', 'CWE-89']).\")\n",
    "    risk_score: str = Field(description=\"Critical, High, Medium, or Low (calculated from impact and likelihood).\")\n",
    "\n",
    "class Threats(BaseModel):\n",
    "    threats: list[Threat]\n",
    "\n",
    "class ThreatsOutput(BaseModel):\n",
    "    threats: list[Threat]\n",
    "    metadata: dict\n",
    "\n",
    "# --- Sample DFD for Testing (if input is empty) ---\n",
    "SAMPLE_DFD = {\n",
    "    \"external_entities\": [\"User\", \"Attacker\"],\n",
    "    \"processes\": [\"Web Application\", \"Authentication Service\"],\n",
    "    \"data_stores\": [\"User Database\"],\n",
    "    \"data_flows\": [\n",
    "        {\n",
    "            \"source\": \"User\",\n",
    "            \"destination\": \"Web Application\",\n",
    "            \"data_description\": \"Login Credentials\",\n",
    "            \"protocol\": \"HTTP\"\n",
    "        },\n",
    "        {\n",
    "            \"source\": \"Web Application\",\n",
    "            \"destination\": \"User Database\",\n",
    "            \"data_description\": \"Query User Data\",\n",
    "            \"protocol\": \"SQL\"\n",
    "        }\n",
    "    ],\n",
    "    \"trust_boundaries\": [\"Internet to DMZ\", \"DMZ to Internal Network\"]\n",
    "}\n",
    "\n",
    "# --- Load DFD Components ---\n",
    "logger.info(f\"--- Loading DFD components from '{DFD_INPUT_PATH}' ---\")\n",
    "try:\n",
    "    with open(DFD_INPUT_PATH, 'r') as f:\n",
    "        dfd_data = json.load(f)\n",
    "    if not dfd_data:\n",
    "        logger.warning(\"--- DFD data is empty. Using sample DFD for testing ---\")\n",
    "        dfd_data = SAMPLE_DFD\n",
    "    logger.info(\"--- DFD components loaded successfully ---\")\n",
    "except FileNotFoundError:\n",
    "    logger.warning(f\"--- Input file not found at '{DFD_INPUT_PATH}'. Using sample DFD for testing ---\")\n",
    "    dfd_data = SAMPLE_DFD\n",
    "except json.JSONDecodeError:\n",
    "    logger.error(f\"--- FATAL ERROR: Could not parse JSON from '{DFD_INPUT_PATH}' ---\")\n",
    "    logger.error(\"The file may be corrupted or empty. Using sample DFD for testing.\")\n",
    "    dfd_data = SAMPLE_DFD\n",
    "except Exception as e:\n",
    "    logger.error(f\"--- FATAL ERROR: An unexpected error occurred while loading DFD components ---\")\n",
    "    logger.error(f\"Error details: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# --- Improved Prompt Engineering for Threat Generation ---\n",
    "threat_prompt_template = \"\"\"\n",
    "You are a cybersecurity architect specializing in threat modeling using the STRIDE framework. Your task is to generate a complete list of relevant threats based on the provided DFD components in JSON format.\n",
    "\n",
    "STRIDE categories must be exactly one of: \n",
    "- S: Spoofing\n",
    "- T: Tampering\n",
    "- R: Repudiation\n",
    "- I: Information Disclosure\n",
    "- D: Denial of Service\n",
    "- E: Elevation of Privilege\n",
    "\n",
    "Do not use any other categories or variations. Generate threats covering ALL components, including:\n",
    "- External entities (e.g., \"User\")\n",
    "- Processes (e.g., \"Web Application\")\n",
    "- Assets (data stores, e.g., \"User Database\")\n",
    "- Data flows (label as \"Source to Destination\", e.g., \"User to Web Application\")\n",
    "- Trust boundaries (e.g., \"Internet to DMZ\")\n",
    "\n",
    "For each component, explicitly consider all six STRIDE categories (S, T, R, I, D, E) and generate threats for each where realistically applicable, aiming for at least 5-6 threats per component to ensure broad and comprehensive coverage. Justify omissions internally if a category truly does not apply, but prioritize inclusion to avoid gaps.\n",
    "\n",
    "For each threat, output strictly in this JSON structure:\n",
    "{{\n",
    "  \"component_name\": \"Affected component (e.g., 'User to Web Application' or 'User Database')\",\n",
    "  \"stride_category\": \"One letter: S, T, R, I, D, or E\",\n",
    "  \"threat_description\": \"Clear, specific description tied to the component, including attack vectors (e.g., 'via MITM on weak TLS leading to PII exposure and regulatory fines'). Reference protocols from the DFD (e.g., HTTPS, AMQP).\",\n",
    "  \"mitigation_suggestion\": \"Practical, actionable mitigation (e.g., 'Implement HTTPS with certificate pinning and HSTS').\",\n",
    "  \"impact\": \"Low, Medium, or High\",\n",
    "  \"likelihood\": \"Low, Medium, or High\",\n",
    "  \"references\": [\"Array of 1-3 valid strings (e.g., 'OWASP A01:2021', 'NIST SP 800-53 SC-28', 'CWE-89')\"],\n",
    "  \"risk_score\": \"Critical, High, Medium, or Low (calculate as: Critical if Impact=High and Likelihood=Medium/High; High if Impact=High and Likelihood=Low or Impact=Medium and Likelihood=High; Medium if Impact=Medium and Likelihood=Medium/Low or Impact=Low and Likelihood=High; Low otherwise)\"\n",
    "}}\n",
    "\n",
    "Think step-by-step internally before generating:\n",
    "1. Parse the DFD JSON: Explicitly list all external_entities, processes, assets (data_stores), data_flows (as 'source to destination'), and trust_boundaries. Ensure every item is addressed.\n",
    "2. For each listed component, brainstorm applicable STRIDE threats: Consider all six categories, identifying typical risks (e.g., data flows vulnerable to T and I due to transit; processes to D and E from overload or vulns; data stores to I at rest). Generate at least one threat per category unless impossible, to achieve 5-6 per component.\n",
    "3. Make threats realistic and specific: Include attack vectors (e.g., SQL injection for tampering), consequences (e.g., data breach leading to fines), and reference DFD protocols/architecture.\n",
    "4. Avoid duplicates: Ensure no identical threats across components; vary descriptions even for similar risks.\n",
    "5. Assign impact/likelihood with justification: Base on exposure (e.g., public-facing = higher likelihood) and calculate risk_score accurately.\n",
    "6. Use only valid references from: OWASP Top 10 2021 (A01-A10 only, e.g., A03:2021 for Injection), NIST SP 800-series (e.g., 800-53, 800-63B, 800-52), CWE (e.g., CWE-89), MITRE ATT&CK (e.g., T1071). Limit to 1-3 per threat; do not invent invalid ones like A11.\n",
    "\n",
    "Examples of good threats:\n",
    "{{\n",
    "  \"component_name\": \"User to Web Application\",\n",
    "  \"stride_category\": \"S\",\n",
    "  \"threat_description\": \"Attacker spoofs user identity via phishing to send fake login credentials over HTTP, leading to account takeover and unauthorized access.\",\n",
    "  \"mitigation_suggestion\": \"Implement strong authentication such as OAuth 2.0 with JWT tokens and MFA.\",\n",
    "  \"impact\": \"High\",\n",
    "  \"likelihood\": \"Medium\",\n",
    "  \"references\": [\"OWASP A05:2021\", \"NIST SP 800-63B\", \"CWE-287\"],\n",
    "  \"risk_score\": \"Critical\"\n",
    "}},\n",
    "{{\n",
    "  \"component_name\": \"User Database\",\n",
    "  \"stride_category\": \"I\",\n",
    "  \"threat_description\": \"Unauthorized access via SQL injection leading to data leakage of sensitive PII, resulting in privacy violations and fines.\",\n",
    "  \"mitigation_suggestion\": \"Encrypt data at rest using AES-256, implement parameterized queries, and enforce least-privilege access controls.\",\n",
    "  \"impact\": \"High\",\n",
    "  \"likelihood\": \"Medium\",\n",
    "  \"references\": [\"OWASP A04:2021\", \"NIST SP 800-53 SC-28\", \"CWE-200\"],\n",
    "  \"risk_score\": \"Critical\"\n",
    "}}\n",
    "\n",
    "Negative examples to avoid:\n",
    "- Invalid reference like \"OWASP A11:2021\" (Top 10 only has A01-A10).\n",
    "- Generic description like \"Unauthorized access to database leading to data leakage\" (add vectors/consequences).\n",
    "- Missing STRIDE coverage without internal justification.\n",
    "- Fewer than 5 threats per component, leading to gaps.\n",
    "\n",
    "DFD Components JSON:\n",
    "{dfd_json}\n",
    "\n",
    "Output ONLY a JSON object with:\n",
    "- \"threats\": [array of threat objects, sorted by risk_score descending (Critical first, then High, Medium, Low)]\n",
    "\n",
    "Do not include metadata or any other keys. Output ONLY the JSON, with no additional text, commentary, reasoning, or formatting.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# --- Validation Prompt Template ---\n",
    "validation_prompt_template = \"\"\"\n",
    "You are a JSON validator for threat modeling outputs. Your task is to validate and correct the following threats JSON to ensure:\n",
    "- It is valid JSON.\n",
    "- Each threat matches the required schema: component_name, stride_category (S/T/R/I/D/E), threat_description, mitigation_suggestion, impact (Low/Medium/High), likelihood (Low/Medium/High), references (list of 1-3 strings), risk_score (Critical/High/Medium/Low).\n",
    "- No duplicates.\n",
    "- Risk scores are correctly calculated based on impact and likelihood.\n",
    "- References are valid (from OWASP, NIST, CWE, MITRE).\n",
    "- Threats are sorted by risk_score descending (Critical > High > Medium > Low).\n",
    "\n",
    "If invalid or improvable, correct it. If valid, return the original.\n",
    "\n",
    "Input Threats JSON:\n",
    "{threats_json}\n",
    "\n",
    "Output ONLY the corrected JSON object with key \"threats\": [array of threat objects]. No other text or explanations.\n",
    "\"\"\"\n",
    "\n",
    "# --- Invocation and Output ---\n",
    "logger.info(\"\\n--- Invoking Local LLM to generate STRIDE threats ---\")\n",
    "try:\n",
    "    # Prepare the generation prompt with DFD JSON\n",
    "    dfd_json_string = json.dumps(dfd_data, indent=2)\n",
    "    gen_prompt = threat_prompt_template.format(dfd_json=dfd_json_string)\n",
    "\n",
    "    # Log the prompt for debugging\n",
    "    logger.info(f\"--- Generation Prompt sent to LLM ---\\n{gen_prompt}\")\n",
    "\n",
    "    # Call raw Ollama for response debugging\n",
    "    raw_gen_response = ollama_client.chat(model=LLM_MODEL, messages=[{\"role\": \"user\", \"content\": gen_prompt}])\n",
    "    logger.info(f\"--- Raw LLM Generation Response ---\\n{raw_gen_response['message']['content']}\")\n",
    "\n",
    "    # Invoke with Instructor for structured output\n",
    "    threats_obj = client.chat.completions.create(\n",
    "        model=LLM_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": gen_prompt}],\n",
    "        response_model=Threats,\n",
    "        max_retries=5  # Retries for validation failures\n",
    "    )\n",
    "    logger.info(\"--- Structured threat generation successful ---\")\n",
    "\n",
    "    threats_dict = threats_obj.model_dump()\n",
    "\n",
    "    # Prepare validation prompt\n",
    "    threats_json_string = json.dumps(threats_dict, indent=2)\n",
    "    val_prompt = validation_prompt_template.format(threats_json=threats_json_string)\n",
    "\n",
    "    # Log the validation prompt\n",
    "    logger.info(f\"--- Validation Prompt sent to LLM ---\\n{val_prompt}\")\n",
    "\n",
    "    # Call raw Ollama for validation response\n",
    "    raw_val_response = ollama_client.chat(model=LLM_MODEL, messages=[{\"role\": \"user\", \"content\": val_prompt}])\n",
    "    logger.info(f\"--- Raw LLM Validation Response ---\\n{raw_val_response['message']['content']}\")\n",
    "\n",
    "    # Parse validated response\n",
    "    try:\n",
    "        validated_threats = json.loads(raw_val_response['message']['content'])\n",
    "        threats_dict = {\"threats\": validated_threats.get(\"threats\", threats_dict[\"threats\"])}\n",
    "        logger.info(\"--- Threats validated and parsed successfully ---\")\n",
    "    except json.JSONDecodeError:\n",
    "        logger.warning(\"--- Validation parsing failed; using original threats ---\")\n",
    "\n",
    "    # Add metadata manually\n",
    "    threats_dict[\"metadata\"] = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"source_dfd\": DFD_INPUT_PATH\n",
    "    }\n",
    "\n",
    "    # Validate against full schema\n",
    "    try:\n",
    "        validated = ThreatsOutput(**threats_dict)\n",
    "        logger.info(\"--- JSON output validated successfully against schema ---\")\n",
    "    except ValidationError as ve:\n",
    "        logger.error(f\"--- JSON validation failed: {ve} ---\")\n",
    "        # Fallback: Try manual parsing of raw generation response\n",
    "        try:\n",
    "            raw_json = json.loads(raw_gen_response['message']['content'])\n",
    "            threats_dict = {\"threats\": raw_json.get(\"threats\", []), \"metadata\": threats_dict[\"metadata\"]}\n",
    "            validated = ThreatsOutput(**threats_dict)\n",
    "            logger.info(\"--- Fallback manual parsing succeeded ---\")\n",
    "        except Exception as pe:\n",
    "            logger.error(f\"--- Manual parsing failed: {pe} ---\")\n",
    "            raise\n",
    "\n",
    "    # Save to file\n",
    "    with open(THREATS_OUTPUT_PATH, 'w') as f:\n",
    "        json.dump(threats_dict, f, indent=2)\n",
    "\n",
    "    logger.info(\"\\n--- LLM Output (Identified Threats) ---\")\n",
    "    print(json.dumps(threats_dict, indent=2))\n",
    "    logger.info(f\"\\n--- Identified threats successfully saved to '{THREATS_OUTPUT_PATH}' ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"\\n--- An error occurred during threat generation ---\")\n",
    "    logger.error(f\"Error: {e}\")\n",
    "    logger.error(\"This could be due to Ollama not enforcing JSON strictly or connection issues on port 5080. Check raw response and adjust prompt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda47710-d7ff-4428-8e2e-ed52320ff48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-28 13:18:01,977 - INFO - --- Setting up RAG pipeline ---\n",
      "2025-07-28 13:18:01,978 - INFO - Use pytorch device_name: mps\n",
      "2025-07-28 13:18:01,978 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n",
      "2025-07-28 13:18:04,729 - INFO - --- No existing FAISS index found. Building a new one. ---\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 4631.52it/s]\n",
      "0it [00:00, ?it/s]\n",
      "2025-07-28 13:18:04,737 - INFO - --- Creating FAISS index from 105 document chunks. This may take a moment... ---\n",
      "/Users/jeffreyvonrotz/SynologyDrive/Projects/Threatalicious/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "2025-07-28 13:18:06,856 - INFO - --- FAISS index created and saved to 'faiss_index' ---\n",
      "2025-07-28 13:18:06,869 - INFO - --- OpenAI client initialized successfully ---\n",
      "2025-07-28 13:18:06,871 - INFO - --- Loading DFD components from './output/dfd_components.json' ---\n",
      "2025-07-28 13:18:06,871 - INFO - \n",
      "--- Invoking LLM with RAG to generate STRIDE threats ---\n",
      "2025-07-28 13:18:06,871 - INFO - \n",
      "--- Analyzing component: {\"type\": \"external_entities\", \"details\": \"U\"} ---\n",
      "2025-07-28 13:18:07,707 - INFO - --- Retrieved RAG context for prompt ---\n"
     ]
    }
   ],
   "source": [
    "# --- Dependencies ---\n",
    "# Ensure you have these packages installed. You can install them using pip:\n",
    "# pip install openai pydantic logging python-dotenv langchain langchain_community langchain_huggingface faiss-cpu pypdf sentence-transformers\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import logging\n",
    "from openai import OpenAI\n",
    "\n",
    "# RAG specific imports\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# --- Configuration ---\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"llama-3.3-70b-instruct\")\n",
    "INPUT_DIR = os.getenv(\"INPUT_DIR\", \"./output\")\n",
    "DFD_INPUT_PATH = os.getenv(\"DFD_INPUT_PATH\", os.path.join(INPUT_DIR, \"dfd_components.json\"))\n",
    "THREATS_OUTPUT_PATH = os.getenv(\"THREATS_OUTPUT_PATH\", os.path.join(INPUT_DIR, \"identified_threats.json\"))\n",
    "\n",
    "# RAG Configuration\n",
    "RAG_DOCS_DIR = \"rag_docs\"\n",
    "FAISS_INDEX_PATH = \"faiss_index\"\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "os.makedirs(RAG_DOCS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def setup_rag_pipeline():\n",
    "    \"\"\"Initializes the RAG pipeline by creating or loading a FAISS vector store.\"\"\"\n",
    "    logger.info(\"--- Setting up RAG pipeline ---\")\n",
    "    \n",
    "    # Use a standard, effective open-source embedding model\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    if os.path.exists(FAISS_INDEX_PATH):\n",
    "        logger.info(f\"--- Loading existing FAISS index from '{FAISS_INDEX_PATH}' ---\")\n",
    "        db = FAISS.load_local(FAISS_INDEX_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "    else:\n",
    "        logger.info(\"--- No existing FAISS index found. Building a new one. ---\")\n",
    "        \n",
    "        documents = []\n",
    "        \n",
    "        # Load PDFs\n",
    "        pdf_loader = DirectoryLoader(RAG_DOCS_DIR, glob=\"**/*.pdf\", loader_cls=PyPDFLoader, show_progress=True, use_multithreading=True)\n",
    "        documents.extend(pdf_loader.load())\n",
    "        \n",
    "        # Load Markdown files\n",
    "        md_loader = DirectoryLoader(RAG_DOCS_DIR, glob=\"**/*.md\", loader_cls=TextLoader, show_progress=True, use_multithreading=True)\n",
    "        documents.extend(md_loader.load())\n",
    "        \n",
    "        # Load plain text files\n",
    "        txt_loader = DirectoryLoader(RAG_DOCS_DIR, glob=\"**/*.txt\", loader_cls=TextLoader, show_progress=True, use_multithreading=True)\n",
    "        documents.extend(txt_loader.load())\n",
    "        \n",
    "        # You can add more loaders here for additional formats, e.g.:\n",
    "        # from langchain_community.document_loaders import Docx2txtLoader\n",
    "        # docx_loader = DirectoryLoader(RAG_DOCS_DIR, glob=\"**/*.docx\", loader_cls=Docx2txtLoader, show_progress=True, use_multithreading=True)\n",
    "        # documents.extend(docx_loader.load())\n",
    "        # Note: Requires additional pip install docx2txt\n",
    "        \n",
    "        # For even more formats (e.g., DOCX, PPTX, CSV, etc.), consider installing 'unstructured[all-docs]' and using UnstructuredFileLoader as default.\n",
    "\n",
    "        if not documents:\n",
    "            logger.error(f\"--- FATAL: No supported documents (e.g., .pdf, .md, .txt) were found in the '{RAG_DOCS_DIR}' directory. ---\")\n",
    "            logger.error(\"--- Please add your security documents (e.g., OWASP PDFs or Markdown files) to this directory. ---\")\n",
    "            raise ValueError(f\"No supported documents found in the '{RAG_DOCS_DIR}' directory. Please add security documents.\")\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        \n",
    "        logger.info(f\"--- Creating FAISS index from {len(docs)} document chunks. This may take a moment... ---\")\n",
    "        db = FAISS.from_documents(docs, embeddings)\n",
    "        db.save_local(FAISS_INDEX_PATH)\n",
    "        logger.info(f\"--- FAISS index created and saved to '{FAISS_INDEX_PATH}' ---\")\n",
    "        \n",
    "    return db\n",
    "\n",
    "# --- Initialize RAG and OpenAI Client ---\n",
    "try:\n",
    "    rag_db = setup_rag_pipeline()\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://api.scaleway.ai/4a8fd76b-8606-46e6-afe6-617ce8eeb948/v1\",\n",
    "        api_key=os.getenv(\"SCW_SECRET_KEY\")\n",
    "    )\n",
    "    logger.info(\"--- OpenAI client initialized successfully ---\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"--- Failed to initialize services: {e} ---\")\n",
    "    raise\n",
    "\n",
    "# --- Threat Schema for Validation ---\n",
    "class Threat(BaseModel):\n",
    "    component_name: str\n",
    "    stride_category: str\n",
    "    threat_description: str\n",
    "    mitigation_suggestion: str\n",
    "    impact: str\n",
    "    likelihood: str\n",
    "    references: list[str]\n",
    "    risk_score: str\n",
    "\n",
    "# Class to match the expected final output structure\n",
    "class ThreatsOutput(BaseModel):\n",
    "    threats: list[Threat]\n",
    "    metadata: dict\n",
    "\n",
    "# --- Sample DFD for Testing ---\n",
    "SAMPLE_DFD = {\n",
    "    \"external_entities\": [\"User\"], \"processes\": [\"Web Application\", \"Authentication Service\"],\n",
    "    \"data_stores\": [\"User Database\"], \"data_flows\": [\n",
    "        {\"source\": \"User\", \"destination\": \"Web Application\", \"data_description\": \"Login Credentials\", \"protocol\": \"HTTP\"},\n",
    "        {\"source\": \"Web Application\", \"destination\": \"User Database\", \"data_description\": \"Query User Data\", \"protocol\": \"SQL\"}\n",
    "    ], \"trust_boundaries\": [\"Internet to DMZ\"]\n",
    "}\n",
    "\n",
    "# --- Load DFD Components ---\n",
    "logger.info(f\"--- Loading DFD components from '{DFD_INPUT_PATH}' ---\")\n",
    "try:\n",
    "    with open(DFD_INPUT_PATH, 'r') as f:\n",
    "        dfd_data = json.load(f)\n",
    "    if not dfd_data:\n",
    "        dfd_data = SAMPLE_DFD\n",
    "except FileNotFoundError:\n",
    "    dfd_data = SAMPLE_DFD\n",
    "except Exception as e:\n",
    "    logger.error(f\"FATAL: Error loading DFD: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# --- RAG-Augmented Prompt Template for Threat Generation ---\n",
    "# This prompt is now focused on generating threats for a SINGLE component using RAG context.\n",
    "threat_prompt_template_rag = \"\"\"\n",
    "You are a cybersecurity architect specializing in threat modeling. Based on the DFD component and the provided security context, generate a list of 2-3 realistic and specific threats.\n",
    "\n",
    "**DFD Component to Analyze:**\n",
    "{component_info}\n",
    "\n",
    "**Security Context from Knowledge Base (use this for accuracy):**\n",
    "'''\n",
    "{rag_context}\n",
    "'''\n",
    "\n",
    "**Instructions:**\n",
    "1.  Generate 2-3 distinct threats for the component, considering all STRIDE categories (S, T, R, I, D, E).\n",
    "2.  For each threat, use the provided Security Context to create specific descriptions, mitigations, and **accurate references**. Do not invent references.\n",
    "3.  Calculate the risk score based on impact and likelihood.\n",
    "4.  Output ONLY a valid JSON object with a single key \"threats\", containing a list of threat objects. Do not include any other text or commentary.\n",
    "\n",
    "**JSON Threat Object Schema:**\n",
    "{{\n",
    "  \"component_name\": \"string\",\n",
    "  \"stride_category\": \"S, T, R, I, D, or E\",\n",
    "  \"threat_description\": \"string\",\n",
    "  \"mitigation_suggestion\": \"string\",\n",
    "  \"impact\": \"Low, Medium, or High\",\n",
    "  \"likelihood\": \"Low, Medium, or High\",\n",
    "  \"references\": [\"list of strings, e.g., 'OWASP A01:2021', 'CWE-89'\"],\n",
    "  \"risk_score\": \"Critical, High, Medium, or Low\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "# --- Main Invocation Logic ---\n",
    "logger.info(\"\\n--- Invoking LLM with RAG to generate STRIDE threats ---\")\n",
    "all_threats = []\n",
    "try:\n",
    "    # Consolidate all DFD components into a single list for iteration\n",
    "    components_to_analyze = []\n",
    "    for key, value in dfd_data.items():\n",
    "        if isinstance(value, list):\n",
    "            for item in value:\n",
    "                components_to_analyze.append({\"type\": key, \"details\": item})\n",
    "\n",
    "    # Iterate through each component, using RAG to generate threats\n",
    "    for component in components_to_analyze:\n",
    "        component_str = json.dumps(component)\n",
    "        logger.info(f\"\\n--- Analyzing component: {component_str} ---\")\n",
    "\n",
    "        # 1. Query RAG database for relevant context\n",
    "        retrieved_docs = rag_db.similarity_search(component_str, k=3) # k=3 retrieves top 3 chunks\n",
    "        rag_context = \"\\n---\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "        \n",
    "        logger.info(f\"--- Retrieved RAG context for prompt ---\")\n",
    "\n",
    "        # 2. Prepare and send the prompt to the LLM\n",
    "        prompt = threat_prompt_template_rag.format(component_info=component_str, rag_context=rag_context)\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=LLM_MODEL,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            max_tokens=2048,\n",
    "            temperature=0.5\n",
    "        )\n",
    "        \n",
    "        # 3. Parse and collect the generated threats\n",
    "        response_content = response.choices[0].message.content\n",
    "        try:\n",
    "            generated_threats = json.loads(response_content).get(\"threats\", [])\n",
    "            all_threats.extend(generated_threats)\n",
    "            logger.info(f\"--- Successfully generated {len(generated_threats)} threats for component ---\")\n",
    "        except (json.JSONDecodeError, AttributeError) as e:\n",
    "            logger.warning(f\"--- Could not parse LLM response for component {component_str}: {e} ---\")\n",
    "            logger.debug(f\"Raw Response: {response_content}\")\n",
    "\n",
    "    # --- Final Processing and Validation ---\n",
    "    # Sort threats by risk score (descending)\n",
    "    risk_order = {\"Critical\": 4, \"High\": 3, \"Medium\": 2, \"Low\": 1}\n",
    "    all_threats.sort(key=lambda t: risk_order.get(t.get('risk_score', 'Low'), 0), reverse=True)\n",
    "\n",
    "    # Prepare the final output structure\n",
    "    final_output = {\n",
    "        \"threats\": all_threats,\n",
    "        \"metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"source_dfd\": DFD_INPUT_PATH,\n",
    "            \"llm_model\": LLM_MODEL,\n",
    "            \"rag_index\": FAISS_INDEX_PATH\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Validate final output with Pydantic\n",
    "    try:\n",
    "        validated_output = ThreatsOutput(**final_output)\n",
    "        logger.info(\"--- Final JSON output validated successfully against schema ---\")\n",
    "    except ValidationError as ve:\n",
    "        logger.error(f\"--- FINAL JSON VALIDATION FAILED: {ve} ---\")\n",
    "        # Still save the raw output for manual inspection\n",
    "        \n",
    "    # Save to file\n",
    "    with open(THREATS_OUTPUT_PATH, 'w') as f:\n",
    "        json.dump(final_output, f, indent=2)\n",
    "\n",
    "    logger.info(\"\\n--- LLM RAG Output (Identified Threats) ---\")\n",
    "    print(json.dumps(final_output, indent=2))\n",
    "    logger.info(f\"\\n--- Identified threats successfully saved to '{THREATS_OUTPUT_PATH}' ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"\\n--- An error occurred during the RAG-based threat generation process ---\")\n",
    "    logger.error(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b793d59d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
